{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e33cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from googletrans import Translator\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.under_sampling import InstanceHardnessThreshold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from tqdm import tqdm  \n",
    "from googletrans import Translator\n",
    "# Translation\n",
    "from tqdm import tqdm  \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler, EditedNearestNeighbours, OneSidedSelection, InstanceHardnessThreshold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from bidi.algorithm import get_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3e612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "wb = openpyxl.load_workbook('E:/Research_Work/Bangla_CyberBulling_2024/Code & dataset/dataset/Final_Dataset_94k_Bangla_CyberBulling_Combine_Dataset_94k.xlsx')\n",
    "ws = wb['Sheet1']\n",
    "data_rows = []\n",
    "for row in ws['A1':'B94001']:\n",
    "    data_cols = [cell.value for cell in row]\n",
    "    data_rows.append(data_cols)\n",
    "df = pd.DataFrame(data_rows)\n",
    "header = df.iloc[0]\n",
    "df.columns = [header]\n",
    "df = df.iloc[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc617a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df['label'].value_counts()\n",
    "print(\"Class Counts:\\n\", class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29152146",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments = ' '.join(df['comment'].apply(lambda x: ' '.join(map(str, x))).astype(str))\n",
    "\n",
    "rgx = r\"[\\u0980-\\u09FF]+\"\n",
    "wordcloud = WordCloud(font_path='E:/Research_Work/Bangla_CyberBulling_2024/Code & dataset/Dataset/Font/CHANO___.ttf',regexp=rgx, width=2000, height=1300, background_color='white').generate(all_comments)\n",
    "\n",
    "plt.figure(figsize=(30, 15))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63af8272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration\n",
    "print(df.head())\n",
    "print(df.iloc[:, -1].value_counts())\n",
    "print(df.shape)\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Handle Missing Values\n",
    "mode = df.iloc[:, -2].value_counts().index[0]\n",
    "df.iloc[:, -2].fillna(mode, inplace=True)\n",
    "print(df.isna().sum())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b833ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling and Encoding\n",
    "list(df.iloc[:, -1].value_counts().index)\n",
    "df['nlabel'] = df.label.replace(['not bully', 'troll', 'sexual', 'religious', 'threat'], [0, 1, 2, 3, 4])\n",
    "df['noutput'] = df.iloc[:, -1].replace(['bully', 'normal'], [1, 0])\n",
    "print(df.head())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df50f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator()\n",
    "output = []\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    if df.label.values[i] == 'not bully':\n",
    "        output.append('Normal')\n",
    "    else:\n",
    "        output.append('Bully')\n",
    "\n",
    "df['output'] = output\n",
    "df['noutput'] = df.iloc[:, -1].replace(['Bully', 'Normal'], [1, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d14078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a658a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055a0c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stopwords.fileids())\n",
    "sw = stopwords.words('bengali')\n",
    "\n",
    "new_stopwords = stopwords.words('english')\n",
    "new_stopwords.append('SampleWord')\n",
    "\n",
    "df.to_csv('df_english1000.csv')\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "M = len(df)\n",
    "for k in tqdm(range(M)):\n",
    "    text = df.iloc[:, 0].values[k]\n",
    "    txt = re.sub(r'http\\S+', '', text)\n",
    "    txt = re.sub(r'[!@#$%^&*?><,./\\-+`~|:);(❤}{]', '', txt)\n",
    "\n",
    "    text_tokens = word_tokenize(txt)\n",
    "\n",
    "    def detect_benglish(text_tokens):\n",
    "        benglish = False\n",
    "        for j in range(len(text_tokens)):\n",
    "            for i in range(len(text_tokens[j])):\n",
    "                detector = Translator()\n",
    "                txt = text_tokens[j]\n",
    "                if i < len(txt) - 1:\n",
    "                    if detector.detect(txt[i]).lang == 'bn' and detector.detect(txt[i + 1]).lang == 'en' and txt[\n",
    "                        i].isalpha() == True and txt[i + 1].isalpha() == True:\n",
    "                        benglish = True\n",
    "        return benglish\n",
    "\n",
    "    def handle_benglish(text_tokens):\n",
    "        for j in range(len(text_tokens)):\n",
    "            s = []\n",
    "            for i in range(len(text_tokens[j])):\n",
    "                detector = Translator()\n",
    "                txt = text_tokens[j]\n",
    "                if i < len(txt) - 1:\n",
    "                    if detector.detect(txt[i]).lang == 'bn' and detector.detect(txt[i + 1]).lang == 'en' and txt[\n",
    "                        i].isalpha() == True and txt[i + 1].isalpha() == True:\n",
    "                        s.append(i)\n",
    "                    if txt[i] == '|':\n",
    "                        s.append(i)\n",
    "            for i in range(len(s)):\n",
    "                txt = txt.replace(txt[s[i]], txt[s[i]] + \" \")\n",
    "            text_tokens[j] = txt\n",
    "        tstring = str(' '.join(text_tokens)).lower()\n",
    "        text_tokens = word_tokenize(tstring)\n",
    "        return text_tokens\n",
    "\n",
    "    remove_sw = [word for word in text_tokens if not word in sw]\n",
    "    un_items = np.unique(remove_sw)\n",
    "    r_sw = [wordnet_lemmatizer.lemmatize(w) for w in un_items]\n",
    "    bn_tokens = []\n",
    "\n",
    "    def tanslate_bengali(r_sw):\n",
    "        for i in range(len(r_sw)):\n",
    "            bn_tokens.append(translator.translate(r_sw[i], dest='bn').text)\n",
    "        return bn_tokens\n",
    "\n",
    "    bn_token = r_sw\n",
    "    df.iloc[:, 0].values[k] = ' '.join(bn_token)\n",
    "\n",
    "df.iloc[:, -1].value_counts()\n",
    "df.iloc[:, 0]\n",
    "\n",
    "df[:].iloc[:, 0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6bffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05389d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Vectorization (Count)\n",
    "count_vectorizer = CountVectorizer(max_features=20000, tokenizer=word_tokenize, stop_words=stopwords.words('english'))\n",
    "iX_count = count_vectorizer.fit_transform(df[:].iloc[:, 0].values).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a415c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfTransformer()\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(iX_count)\n",
    "iX_tfidf = tf_transformer.transform(iX_count)\n",
    "iX_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d40a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "by = df.iloc[:, -3].values\n",
    "by.shape\n",
    "\n",
    "my = df.iloc[:, -1].values\n",
    "\n",
    "np.unique(by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b61a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalanced Data Handling\n",
    "cc = InstanceHardnessThreshold(random_state=10, estimator=LogisticRegression())\n",
    "X, y = cc.fit_resample(iX_tfidf, by)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c46d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "print('complete')\n",
    "print('train:', X_train.shape, y_train.shape, 'test:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06447f4",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be0b752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have X_train, X_test, y_train, y_test defined somewhere in your code\n",
    "\n",
    "# Part 8: Model Building (Logistic Regression)\n",
    "def build_models_logistic_regression():\n",
    "    print('Building Logistic Regression model...')\n",
    "    logistic_regression = LogisticRegression()\n",
    "    logistic_regression.fit(X_train, y_train)\n",
    "    print('Logistic Regression model built successfully.')\n",
    "    return logistic_regression\n",
    "\n",
    "logistic_regression = build_models_logistic_regression()\n",
    "\n",
    "# Part 9: Model Evaluation (Logistic Regression)\n",
    "def evaluate_model(logistic_regression, X_test, y_test):\n",
    "    y_pred = logistic_regression.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Print the metrics\n",
    "    print(f'Accuracy: {acc*100:.2f}%')\n",
    "    print(f'Precision: {precision*100:.2f}%')\n",
    "    print(f'Recall: {recall*100:.2f}%')\n",
    "    print(f'F1 Score: {f1*100:.2f}%')\n",
    "    \n",
    "    return acc, precision, recall, f1\n",
    "\n",
    "accuracy_logistic_regression, precision_logistic_regression, recall_logistic_regression, f1_logistic_regression = evaluate_model(logistic_regression, X_test, y_test)\n",
    "\n",
    "# Part 10: Confusion Matrix Analysis (Logistic Regression)\n",
    "# Part 10: Confusion Matrix Analysis (Logistic Regression)\n",
    "def confusion_matrix_analysis(logistic_regression, X_test, y_test):\n",
    "    y_pred = logistic_regression.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    class_names = ['not bully', 'troll', 'sexual', 'religious', 'threat']  # Update class names\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=class_names, yticklabels=class_names)\n",
    "    \n",
    "    # Display values on the plot without box and color\n",
    "    for i in range(len(class_names)):\n",
    "        for j in range(len(class_names)):\n",
    "            plt.text(j + 0.5, i + 0.5, f'{cm[i, j]}', ha='center', va='center', color='black', fontsize=10)\n",
    "\n",
    "    plt.title('Confusion Matrix (Logistic Regression)')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.show()\n",
    "\n",
    "confusion_matrix_analysis(logistic_regression, X_test, y_test)\n",
    "\n",
    "\n",
    "# Part 11: ROC Curve (Logistic Regression)\n",
    "def plot_roc_curve(logistic_regression, X_test, y_test, class_names):\n",
    "    y_probs = logistic_regression.predict_proba(X_test)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))  # Adjusted figure size\n",
    "    for i in range(len(class_names)):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_probs[:, i], pos_label=i)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')  # Adjusted class name format\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='grey', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (LR)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "class_names = ['Not Bully', 'Troll', 'Sexual', 'Religious', 'Threat']  # Adjusted class names format\n",
    "plot_roc_curve(logistic_regression, X_test, y_test, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cbdb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficients:', logistic_regression.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6a9ac9",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have X_train, X_test, y_train, y_test defined somewhere in your code\n",
    "\n",
    "# Part 8: Model Building (XGBoost)\n",
    "def build_models_xgboost():\n",
    "    print('Building XGBoost model...')\n",
    "    xgboost_model = XGBClassifier()\n",
    "    xgboost_model.fit(X_train, y_train)\n",
    "    print('XGBoost model built successfully.')\n",
    "    return xgboost_model\n",
    "\n",
    "xgboost_model = build_models_xgboost()\n",
    "\n",
    "# Part 9: Model Evaluation (XGBoost)\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    # Print the metrics\n",
    "    print(f'Accuracy: {acc*100:.2f}%')\n",
    "    print(f'Precision: {precision*100:.2f}%')\n",
    "    print(f'Recall: {recall*100:.2f}%')\n",
    "    print(f'F1 Score: {f1*100:.2f}%')\n",
    "\n",
    "    return acc, precision, recall, f1\n",
    "\n",
    "accuracy_xgboost, precision_xgb, recall_xgb, f1_xgb = evaluate_model(xgboost_model, X_test, y_test)\n",
    "\n",
    "# Part 10: Confusion Matrix Analysis (XGBoost)\n",
    "def confusion_matrix_analysis(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    class_names = ['not bully', 'troll', 'sexual', 'religious', 'threat']  # Update class names\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=class_names, yticklabels=class_names)\n",
    "    \n",
    "    # Display values on the plot without box and color\n",
    "    for i in range(len(class_names)):\n",
    "        for j in range(len(class_names)):\n",
    "            plt.text(j + 0.5, i + 0.5, f'{cm[i, j]}', ha='center', va='center', color='black', fontsize=10)\n",
    "\n",
    "    plt.title('Confusion Matrix (xgboost_model)')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.show()\n",
    "\n",
    "confusion_matrix_analysis(xgboost_model, X_test, y_test)\n",
    "\n",
    "# Part 11: ROC Curve (XGBoost)\n",
    "def plot_roc_curve(model, X_test, y_test, class_names):\n",
    "    y_probs = model.predict_proba(X_test)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))  # Adjusted figure size\n",
    "    for i in range(len(class_names)):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_probs[:, i], pos_label=i)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')  # Adjusted class name format\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='grey', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (XGBoost)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "class_names = ['Not Bully', 'Troll', 'Sexual', 'Religious', 'Threat']  # Adjusted class names format\n",
    "plot_roc_curve(xgboost_model, X_test, y_test, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028971df",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2479b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have X_train, X_test, y_train, y_test defined somewhere in your code\n",
    "\n",
    "# Part 16: Model Building (AdaBoost)\n",
    "def build_models_adaboost(X_train, y_train):\n",
    "    global adaboost_model\n",
    "    print('Building AdaBoost model...')\n",
    "    base_model = DecisionTreeClassifier(max_depth=1)\n",
    "    adaboost_model = AdaBoostClassifier(base_model, n_estimators=50)\n",
    "    adaboost_model.fit(X_train, y_train)\n",
    "    print('AdaBoost model built successfully.')\n",
    "    return adaboost_model\n",
    "\n",
    "adaboost_model = build_models_adaboost(X_train, y_train)\n",
    "\n",
    "# Part 17: Model Evaluation (AdaBoost)\n",
    "def evaluate_model_adaboost(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {acc*100:.2f}%')\n",
    "    \n",
    "    # Additional metrics\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f'Precision: {precision*100:.2f}%')\n",
    "    print(f'Recall: {recall*100:.2f}%')\n",
    "    print(f'F1 Score: {f1*100:.2f}%')\n",
    "    \n",
    "    return acc\n",
    "\n",
    "accuracy_adaboost = evaluate_model_adaboost(adaboost_model, X_test, y_test)\n",
    "\n",
    "# Part 18: Confusion Matrix Analysis (AdaBoost)\n",
    "def confusion_matrix_analysis_adaboost(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    class_names = ['not bully', 'troll', 'sexual', 'religious', 'threat']  # Update class names\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=class_names, yticklabels=class_names)\n",
    "    \n",
    "    # Display values on the plot without box and color\n",
    "    for i in range(len(class_names)):\n",
    "        for j in range(len(class_names)):\n",
    "            plt.text(j + 0.5, i + 0.5, f'{cm[i, j]}', ha='center', va='center', color='black', fontsize=10)\n",
    "\n",
    "    plt.title('Confusion Matrix (AdaBoost)')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.show()\n",
    "\n",
    "confusion_matrix_analysis_adaboost(adaboost_model, X_test, y_test)\n",
    "\n",
    "\n",
    "# Part 19: ROC Curve (AdaBoost)\n",
    "def plot_roc_curve_adaboost(model, X_test, y_test, class_names):\n",
    "    y_probs = model.predict_proba(X_test)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))  # Adjusted figure size\n",
    "    for i in range(len(class_names)):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_probs[:, i], pos_label=i)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')  # Adjusted class name format\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='grey', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (AdaBoost)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "class_names = ['Not Bully', 'Troll', 'Sexual', 'Religious', 'Threat']  # Adjusted class names format\n",
    "plot_roc_curve_adaboost(adaboost_model, X_test, y_test, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb137ae",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8032e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have X_train, X_test, y_train, y_test defined somewhere in your code\n",
    "\n",
    "# Part 23: Model Building (Random Forest)\n",
    "def build_models_random_forest(X_train, y_train):\n",
    "    global random_forest_model\n",
    "    print('Building Random Forest model...')\n",
    "    random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    random_forest_model.fit(X_train, y_train)\n",
    "    print('Random Forest model built successfully.')\n",
    "    return random_forest_model\n",
    "\n",
    "random_forest_model = build_models_random_forest(X_train, y_train)\n",
    "\n",
    "# Part 24: Model Evaluation (Random Forest)\n",
    "def evaluate_model_random_forest(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {acc*100:.2f}%')\n",
    "    \n",
    "    # Additional metrics\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f'Precision: {precision*100:.2f}%')\n",
    "    print(f'Recall: {recall*100:.2f}%')\n",
    "    print(f'F1 Score: {f1*100:.2f}%')\n",
    "    \n",
    "    return acc\n",
    "\n",
    "accuracy_random_forest = evaluate_model_random_forest(random_forest_model, X_test, y_test)\n",
    "\n",
    "# Part 25: Confusion Matrix Analysis (Random Forest)\n",
    "def confusion_matrix_analysis_random_forest(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    class_names = ['not bully', 'troll', 'sexual', 'religious', 'threat']  # Update class names\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=class_names, yticklabels=class_names)\n",
    "    \n",
    "    # Display values on the plot without box and color\n",
    "    for i in range(len(class_names)):\n",
    "        for j in range(len(class_names)):\n",
    "            plt.text(j + 0.5, i + 0.5, f'{cm[i, j]}', ha='center', va='center', color='black', fontsize=10)\n",
    "\n",
    "    plt.title('Confusion Matrix (Random Forest)')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.show()\n",
    "\n",
    "confusion_matrix_analysis_random_forest(random_forest_model, X_test, y_test)\n",
    "\n",
    "# Part 19: ROC Curve (AdaBoost)\n",
    "def roc_curve_analysis_random_forest(random_forest_model, X_test, y_test, class_names):\n",
    "    y_probs = random_forest_model.predict_proba(X_test)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))  # Adjusted figure size\n",
    "    for i in range(len(class_names)):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_probs[:, i], pos_label=i)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')  # Adjusted class name format\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='grey', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (RF)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "class_names = ['Not Bully', 'Troll', 'Sexual', 'Religious', 'Threat']  # Adjusted class names format\n",
    "roc_curve_analysis_random_forest(random_forest_model, X_test, y_test, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a46532",
   "metadata": {},
   "source": [
    "# K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60483274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have X_train, X_test, y_train, y_test defined somewhere in your code\n",
    "\n",
    "# Part 27: Model Building (K-NN)\n",
    "def build_models_knn(X_train, y_train):\n",
    "    global knn_model\n",
    "    print('Building K-NN model...')\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    print('K-NN model built successfully.')\n",
    "    return knn_model\n",
    "\n",
    "knn_model = build_models_knn(X_train, y_train)\n",
    "\n",
    "# Part 28: Model Evaluation (K-NN)\n",
    "def evaluate_model_knn(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {acc*100:.2f}%')\n",
    "    \n",
    "    # Additional metrics\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f'Precision: {precision*100:.2f}%')\n",
    "    print(f'Recall: {recall*100:.2f}%')\n",
    "    print(f'F1 Score: {f1*100:.2f}%')\n",
    "    \n",
    "    return acc\n",
    "\n",
    "accuracy_knn = evaluate_model_knn(knn_model, X_test, y_test)\n",
    "\n",
    "# Part 29: Confusion Matrix Analysis (K-NN)\n",
    "def confusion_matrix_analysis_knn(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    class_names = ['not bully', 'troll', 'sexual', 'religious', 'threat']  # Update class names\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=class_names, yticklabels=class_names)\n",
    "    \n",
    "    # Display values on the plot without box and color\n",
    "    for i in range(len(class_names)):\n",
    "        for j in range(len(class_names)):\n",
    "            plt.text(j + 0.5, i + 0.5, f'{cm[i, j]}', ha='center', va='center', color='black', fontsize=10)\n",
    "\n",
    "    plt.title('Confusion Matrix (K-NN)')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.show()\n",
    "\n",
    "confusion_matrix_analysis_knn(knn_model, X_test, y_test)\n",
    "\n",
    "# Part 19: ROC Curve (AdaBoost)\n",
    "def roc_curve_analysis_knn_model(knn_model, X_test, y_test, class_names):\n",
    "    y_probs = knn_model.predict_proba(X_test)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))  # Adjusted figure size\n",
    "    for i in range(len(class_names)):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_probs[:, i], pos_label=i)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')  # Adjusted class name format\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='grey', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (knn)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "class_names = ['Not Bully', 'Troll', 'Sexual', 'Religious', 'Threat']  # Adjusted class names format\n",
    "roc_curve_analysis_knn_model(knn_model, X_test, y_test, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b35611",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd77c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have X_train, X_test, y_train, y_test defined somewhere in your code\n",
    "\n",
    "# Part 31: Model Building (Bagging with Decision Tree)\n",
    "def build_models_bagging(X_train, y_train):\n",
    "    global bagging_model\n",
    "    print('Building Bagging model...')\n",
    "    base_estimator = DecisionTreeClassifier(max_depth=5)\n",
    "    bagging_model = BaggingClassifier(base_estimator, n_estimators=10, random_state=42)\n",
    "    bagging_model.fit(X_train, y_train)\n",
    "    print('Bagging model built successfully.')\n",
    "    return bagging_model\n",
    "\n",
    "bagging_model = build_models_bagging(X_train, y_train)\n",
    "\n",
    "# Part 32: Model Evaluation (Bagging)\n",
    "def evaluate_model_bagging(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {acc*100:.2f}%')\n",
    "    \n",
    "    # Additional metrics\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f'Precision: {precision*100:.2f}%')\n",
    "    print(f'Recall: {recall*100:.2f}%')\n",
    "    print(f'F1 Score: {f1*100:.2f}%')\n",
    "    \n",
    "    return acc\n",
    "\n",
    "accuracy_bagging = evaluate_model_bagging(bagging_model, X_test, y_test)\n",
    "\n",
    "# Part 33: Confusion Matrix Analysis (Bagging)\n",
    "def confusion_matrix_analysis_bagging(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    class_names = ['not bully', 'troll', 'sexual', 'religious', 'threat']  # Update class names\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=class_names, yticklabels=class_names)\n",
    "    \n",
    "    # Display values on the plot without box and color\n",
    "    for i in range(len(class_names)):\n",
    "        for j in range(len(class_names)):\n",
    "            plt.text(j + 0.5, i + 0.5, f'{cm[i, j]}', ha='center', va='center', color='black', fontsize=10)\n",
    "\n",
    "    plt.title('Confusion Matrix (Bagging)')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.show()\n",
    "    \n",
    "confusion_matrix_analysis_bagging(bagging_model, X_test, y_test)\n",
    "\n",
    "# Part 19: ROC Curve (AdaBoost)\n",
    "def roc_curve_analysis_bagging_model(bagging_model, X_test, y_test, class_names):\n",
    "    y_probs = bagging_model.predict_proba(X_test)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))  # Adjusted figure size\n",
    "    for i in range(len(class_names)):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_probs[:, i], pos_label=i)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')  # Adjusted class name format\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='grey', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (Bagging)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "class_names = ['Not Bully', 'Troll', 'Sexual', 'Religious', 'Threat']  # Adjusted class names format\n",
    "roc_curve_analysis_bagging_model(bagging_model, X_test, y_test, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f768c69",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97799dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have X_train, X_test, y_train, y_test defined somewhere in your code\n",
    "\n",
    "# Part 43: Model Building (MLP)\n",
    "def build_model_mlp(X_train, y_train):\n",
    "    global mlp_model\n",
    "    print('Building MLP model...')\n",
    "    mlp_model = MLPClassifier()\n",
    "    mlp_model.fit(X_train, y_train)\n",
    "    print('MLP model built successfully.')\n",
    "    return mlp_model\n",
    "\n",
    "mlp_model = build_model_mlp(X_train, y_train)\n",
    "\n",
    "# Part 44: Model Evaluation (MLP)\n",
    "def evaluate_model_mlp(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {acc*100:.2f}%')\n",
    "    \n",
    "    # Additional metrics\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f'Precision: {precision*100:.2f}%')\n",
    "    print(f'Recall: {recall*100:.2f}%')\n",
    "    print(f'F1 Score: {f1*100:.2f}%')\n",
    "    \n",
    "    return acc\n",
    "\n",
    "accuracy_mlp = evaluate_model_mlp(mlp_model, X_test, y_test)\n",
    "\n",
    "# Part 45: Confusion Matrix Analysis (MLP)\n",
    "def confusion_matrix_analysis_mlp(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    class_names = ['not bully', 'troll', 'sexual', 'religious', 'threat']  # Update class names\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=class_names, yticklabels=class_names)\n",
    "    \n",
    "    # Display values on the plot without box and color\n",
    "    for i in range(len(class_names)):\n",
    "        for j in range(len(class_names)):\n",
    "            plt.text(j + 0.5, i + 0.5, f'{cm[i, j]}', ha='center', va='center', color='black', fontsize=10)\n",
    "\n",
    "    plt.title('Confusion Matrix (MLP)')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.show()\n",
    "\n",
    "confusion_matrix_analysis_mlp(mlp_model, X_test, y_test)\n",
    "\n",
    "# Part 46: ROC Curve (MLP)\n",
    "def roc_curve_analysis_mlp_model(mlp_model, X_test, y_test, class_names):\n",
    "    y_probs = mlp_model.predict_proba(X_test)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))  # Adjusted figure size\n",
    "    for i in range(len(class_names)):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_probs[:, i], pos_label=i)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')  # Adjusted class name format\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='grey', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (mlp)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "class_names = ['Not Bully', 'Troll', 'Sexual', 'Religious', 'Threat']  # Adjusted class names format\n",
    "roc_curve_analysis_mlp_model(mlp_model, X_test, y_test, class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac7e9ed",
   "metadata": {},
   "source": [
    "# SGDClassifier__ Stochastic Gradient Descent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b96044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have X_train, X_test, y_train, y_test defined somewhere in your code\n",
    "\n",
    "# Part 47: Model Building (SGD Classifier)\n",
    "def build_model_sgd(X_train, y_train):\n",
    "    global sgd_model\n",
    "    print('Building SGD Classifier model...')\n",
    "    sgd_model = SGDClassifier()\n",
    "    sgd_model.fit(X_train, y_train)\n",
    "    print('SGD Classifier model built successfully.')\n",
    "    return sgd_model\n",
    "\n",
    "sgd_model = build_model_sgd(X_train, y_train)\n",
    "\n",
    "# Part 48: Model Evaluation (SGD Classifier)\n",
    "def evaluate_model_sgd(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {acc*100:.2f}%')\n",
    "    \n",
    "    # Additional metrics\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f'Precision: {precision*100:.2f}%')\n",
    "    print(f'Recall: {recall*100:.2f}%')\n",
    "    print(f'F1 Score: {f1*100:.2f}%')\n",
    "    \n",
    "    return acc\n",
    "\n",
    "accuracy_sgd = evaluate_model_sgd(sgd_model, X_test, y_test)\n",
    "\n",
    "# Part 49: Confusion Matrix Analysis (SGD Classifier)\n",
    "def confusion_matrix_analysis_sgd(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    class_names = ['not bully', 'troll', 'sexual', 'religious', 'threat']  # Update class names\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=class_names, yticklabels=class_names)\n",
    "    \n",
    "    # Display values on the plot without box and color\n",
    "    for i in range(len(class_names)):\n",
    "        for j in range(len(class_names)):\n",
    "            plt.text(j + 0.5, i + 0.5, f'{cm[i, j]}', ha='center', va='center', color='black', fontsize=10)\n",
    "\n",
    "    plt.title('Confusion Matrix (SGD Classifier)')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.show()\n",
    "\n",
    "confusion_matrix_analysis_sgd(sgd_model, X_test, y_test)\n",
    "\n",
    "\n",
    "# Part 50: ROC Curve (SGD Classifier)\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def roc_curve_analysis_sgd_model(sgd_model, X_test, y_test, class_names):\n",
    "    # Fit the SGDClassifier first\n",
    "    sgd_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calibrate the classifier to get probability estimates\n",
    "    calibrated_sgd = CalibratedClassifierCV(sgd_model, method='sigmoid', cv='prefit')\n",
    "    calibrated_sgd.fit(X_train, y_train)\n",
    "    \n",
    "    # Get probability estimates\n",
    "    y_probs = calibrated_sgd.predict_proba(X_test)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    for i in range(len(class_names)):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_probs[:, i], pos_label=i)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='grey', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (SGD)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Assuming you have already defined and trained your SGDClassifier\n",
    "sgd_model = SGDClassifier(random_state=42)  # Remove loss='log'\n",
    "\n",
    "class_names = ['Not Bully', 'Troll', 'Sexual', 'Religious', 'Threat']\n",
    "roc_curve_analysis_sgd_model(sgd_model, X_test, y_test, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2f38df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD+LR+MLP (Stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a61377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.base import is_classifier\n",
    "\n",
    "# Assuming you have X_train, X_test, y_train, y_test defined somewhere in your code\n",
    "# Part 51: Model Building (Stacking Classifier: SGD, MLP, RandomForest)\n",
    "def build_stacking_classifier(X_train, y_train):\n",
    "    global stacking_model\n",
    "    print('Building Stacking Classifier model...')\n",
    "    # Creating instances of the base classifiers\n",
    "    sgd_classifier = SGDClassifier()\n",
    "    mlp_classifier = MLPClassifier()\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "    # Check if classifiers support probability estimates\n",
    "    classifiers_with_proba = [(name, clf) for name, clf in [('sgd', sgd_classifier), ('mlp', mlp_classifier), ('rf', rf_classifier)] if is_classifier(clf) and hasattr(clf, \"predict_proba\")]\n",
    "    if not classifiers_with_proba:\n",
    "        raise ValueError(\"None of the base classifiers support probability estimates. Stacking requires probability estimates.\")\n",
    "\n",
    "    # Creating the Stacking Classifier\n",
    "    stacking_model = StackingClassifier(classifiers_with_proba, final_estimator=SGDClassifier(), stack_method='auto', n_jobs=-1)\n",
    "    \n",
    "    # Fitting the model\n",
    "    stacking_model.fit(X_train, y_train)\n",
    "    print('Stacking Classifier model built successfully.')\n",
    "    return stacking_model\n",
    "# Building the Stacking Classifier (assuming X_train, X_test, y_train, y_test are defined)\n",
    "stacking_model = build_stacking_classifier(X_train, y_train)\n",
    "\n",
    "# Part 52: Model Evaluation (Stacking Classifier)\n",
    "def evaluate_stacking_classifier(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {acc*100:.2f}%')\n",
    "    \n",
    "    # Additional metrics\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f'Precision: {precision*100:.2f}%')\n",
    "    print(f'Recall: {recall*100:.2f}%')\n",
    "    print(f'F1 Score: {f1*100:.2f}%')\n",
    "    \n",
    "    confusion_matrix_analysis(model, X_test, y_test)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "# Part 53: Confusion Matrix Analysis (Stacking Classifier)\n",
    "def confusion_matrix_analysis(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    class_names = ['not bully', 'troll', 'sexual', 'religious', 'threat']  # Update class names\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=class_names, yticklabels=class_names)\n",
    "    \n",
    "    # Display values on the plot without box and color\n",
    "    for i in range(len(class_names)):\n",
    "        for j in range(len(class_names)):\n",
    "            plt.text(j + 0.5, i + 0.5, f'{cm[i, j]}', ha='center', va='center', color='black', fontsize=10)\n",
    "\n",
    "    plt.title('Confusion Matrix (Stacking Classifier)')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.show()\n",
    "\n",
    "# Evaluating the Stacking Classifier\n",
    "accuracy_stacking = evaluate_stacking_classifier(stacking_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168377f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 54: ROC Curve (LightGBM with Default Parameters)\n",
    "def roc_curve_analysis_stacking_model(stacking_model, X_test, y_test, class_names):\n",
    "    y_probs = stacking_model.predict_proba(X_test)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))  # Adjusted figure size\n",
    "    for i in range(len(class_names)):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_probs[:, i], pos_label=i)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')  # Adjusted class name format\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='grey', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (stacking)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show() \n",
    "\n",
    "class_names = ['Not Bully', 'Troll', 'Sexual', 'Religious', 'Threat']  # Adjusted class names format\n",
    "roc_curve_analysis_stacking_model(stacking_model, X_test, y_test, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfaa484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming you have defined and trained your stacking_model\n",
    "stacking_model.fit(X_train, y_train)  # Make sure to fit the model before using it\n",
    "\n",
    "# Part 53: Classification Report Analysis (Stacking Classifier)\n",
    "def classification_report_analysis(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    class_names = ['not bully', 'troll', 'sexual', 'religious', 'threat']  # Update class names\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "\n",
    "# Evaluating the Stacking Classifier\n",
    "accuracy_stacking = evaluate_stacking_classifier(stacking_model, X_test, y_test)\n",
    "classification_report_analysis(stacking_model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78344a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.base import is_classifier\n",
    "\n",
    "# Assuming you have X_train, X_test, y_train, y_test defined somewhere in your code\n",
    "\n",
    "# Part 51: Model Building (Voting Classifier: SGD, Logistic Regression, MLP)\n",
    "def build_voting_classifier(X_train, y_train):\n",
    "    global voting_model\n",
    "    print('Building Voting Classifier model...')\n",
    "    \n",
    "    # Creating instances of the classifiers\n",
    "    sgd_classifier = SGDClassifier()\n",
    "    lr_classifier = LogisticRegression()\n",
    "    mlp_classifier = MLPClassifier()\n",
    "\n",
    "    # Check if classifiers support probability estimates\n",
    "    classifiers_with_proba = [(name, clf) for name, clf in [('sgd', sgd_classifier), ('lr', lr_classifier), ('mlp', mlp_classifier)] if is_classifier(clf) and hasattr(clf, \"predict_proba\")]\n",
    "\n",
    "    if not classifiers_with_proba:\n",
    "        raise ValueError(\"None of the base classifiers support probability estimates. Soft voting requires probability estimates.\")\n",
    "\n",
    "    # Creating the Voting Classifier\n",
    "    voting_model = VotingClassifier(classifiers_with_proba, voting='soft')  # 'hard' for majority voting\n",
    "    \n",
    "    # Fitting the model\n",
    "    voting_model.fit(X_train, y_train)\n",
    "    \n",
    "    print('Voting Classifier model built successfully.')\n",
    "    return voting_model\n",
    "\n",
    "# Building the Voting Classifier (assuming X_train, X_test, y_train, y_test are defined)\n",
    "voting_model = build_voting_classifier(X_train, y_train)\n",
    "\n",
    "# Part 52: Model Evaluation (Voting Classifier)\n",
    "def evaluate_voting_classifier(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {acc*100:.2f}%')\n",
    "    \n",
    "    # Additional metrics\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f'Precision: {precision*100:.2f}%')\n",
    "    print(f'Recall: {recall*100:.2f}%')\n",
    "    print(f'F1 Score: {f1*100:.2f}%')\n",
    "    \n",
    "    confusion_matrix_analysis(model, X_test, y_test)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "# Part 53: Confusion Matrix Analysis (Voting Classifier)\n",
    "def confusion_matrix_analysis(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    class_names = ['not bully', 'troll', 'sexual', 'religious', 'threat']  # Update class names\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=class_names, yticklabels=class_names)\n",
    "    \n",
    "    # Display values on the plot without box and color\n",
    "    for i in range(len(class_names)):\n",
    "        for j in range(len(class_names)):\n",
    "            plt.text(j + 0.5, i + 0.5, f'{cm[i, j]}', ha='center', va='center', color='black', fontsize=10)\n",
    "\n",
    "    plt.title('Confusion Matrix (Voting Classifier)')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.show()\n",
    "\n",
    "# Evaluating the Voting Classifier\n",
    "accuracy_voting = evaluate_voting_classifier(voting_model, X_test, y_test)\n",
    "\n",
    "# Part 11: ROC Curve (LightGBM with Default Parameters)\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "def roc_curve_analysis_voting_model(voting_model, X_test, y_test, class_names):\n",
    "    y_probs = voting_model.predict_proba(X_test)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))  # Adjusted figure size\n",
    "    for i in range(len(class_names)):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_probs[:, i], pos_label=i)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')  # Adjusted class name format\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='grey', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (voting)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "class_names = ['Not Bully', 'Troll', 'Sexual', 'Religious', 'Threat']  # Adjusted class names format\n",
    "roc_curve_analysis_voting_model(voting_model, X_test, y_test, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2bbd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 11: ROC Curve (LightGBM with Default Parameters)\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "def roc_curve_analysis_voting_model(voting_model, X_test, y_test, class_names):\n",
    "    y_probs = voting_model.predict_proba(X_test)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))  # Adjusted figure size\n",
    "    for i in range(len(class_names)):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_probs[:, i], pos_label=i)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')  # Adjusted class name format\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='grey', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (voting)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "class_names = ['Not Bully', 'Troll', 'Sexual', 'Religious', 'Threat']  # Adjusted class names format\n",
    "roc_curve_analysis_voting_model(voting_model, X_test, y_test, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
