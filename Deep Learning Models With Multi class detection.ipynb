{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e33cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from googletrans import Translator\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.under_sampling import InstanceHardnessThreshold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from tqdm import tqdm  \n",
    "from googletrans import Translator\n",
    "# Translation\n",
    "from tqdm import tqdm  \n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler, EditedNearestNeighbours, OneSidedSelection, InstanceHardnessThreshold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from bidi.algorithm import get_display\n",
    "import re\n",
    "import keras\n",
    "import openpyxl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from googletrans import Translator\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras import Sequential\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "#from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.under_sampling import InstanceHardnessThreshold\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Flatten, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3e612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "wb = openpyxl.load_workbook('E:/Research_Work/Bangla_CyberBulling_2024/Code & dataset/dataset/Final_Dataset_94k_Bangla_CyberBulling_Combine_Dataset_94k.xlsx')\n",
    "ws = wb['Sheet1']\n",
    "data_rows = []\n",
    "for row in ws['A1':'B94001']:\n",
    "    data_cols = [cell.value for cell in row]\n",
    "    data_rows.append(data_cols)\n",
    "df = pd.DataFrame(data_rows)\n",
    "header = df.iloc[0]\n",
    "df.columns = [header]\n",
    "df = df.iloc[1:, :]\n",
    "class_counts = df['label'].value_counts()\n",
    "print(\"Class Counts:\\n\", class_counts)\n",
    "all_comments = ' '.join(df['comment'].apply(lambda x: ' '.join(map(str, x))).astype(str))\n",
    "\n",
    "rgx = r\"[\\u0980-\\u09FF]+\"\n",
    "wordcloud = WordCloud(font_path='E:/Research_Work/Bangla_CyberBulling_2024/Code & dataset/Dataset/Font/CHANO___.ttf',regexp=rgx, width=2000, height=1300, background_color='white').generate(all_comments)\n",
    "\n",
    "plt.figure(figsize=(30, 15))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "# Data Exploration\n",
    "print(df.head())\n",
    "print(df.iloc[:, -1].value_counts())\n",
    "print(df.shape)\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Handle Missing Values\n",
    "mode = df.iloc[:, -2].value_counts().index[0]\n",
    "df.iloc[:, -2].fillna(mode, inplace=True)\n",
    "print(df.isna().sum())\n",
    "print(df.head())\n",
    "# Labeling and Encoding\n",
    "list(df.iloc[:, -1].value_counts().index)\n",
    "df['nlabel'] = df.label.replace(['not bully', 'troll', 'sexual', 'religious', 'threat'], [0, 1, 2, 3, 4])\n",
    "df['noutput'] = df.iloc[:, -1].replace(['bully', 'normal'], [1, 0])\n",
    "print(df.head())\n",
    "print(df.head())\n",
    "translator = Translator()\n",
    "output = []\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    if df.label.values[i] == 'not bully':\n",
    "        output.append('Normal')\n",
    "    else:\n",
    "        output.append('Bully')\n",
    "\n",
    "df['output'] = output\n",
    "df['noutput'] = df.iloc[:, -1].replace(['Bully', 'Normal'], [1, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc3c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Print column names\n",
    "print(\"Column Names:\", df.columns)\n",
    "\n",
    "# Calculate Total Comments, Total Words, and Unique Words for 'troll' and 'not bully' classes\n",
    "class_info = []\n",
    "for label in ['not bully', 'troll', 'sexual', 'religious', 'threat']:\n",
    "    class_data = df[df.iloc[:, 1] == label].iloc[:, 0]\n",
    "    total_comments = len(class_data)\n",
    "    total_words = ' '.join(class_data).split()\n",
    "    unique_words = set(total_words)\n",
    "\n",
    "    class_info.append({\n",
    "        'Class': label,\n",
    "        'Total Comments': total_comments,\n",
    "        'Total Words': len(total_words),\n",
    "        'Unique Words': len(unique_words)\n",
    "    })\n",
    "\n",
    "# Display the results\n",
    "class_info_df = pd.DataFrame(class_info)\n",
    "print(\"\\nClass-wise Information:\")\n",
    "print(class_info_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d14078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055a0c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stopwords.fileids())\n",
    "sw = stopwords.words('bengali')\n",
    "\n",
    "new_stopwords = stopwords.words('english')\n",
    "new_stopwords.append('SampleWord')\n",
    "\n",
    "df.to_csv('df_english1000.csv')\n",
    "\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "M = len(df)\n",
    "for k in tqdm(range(M)):\n",
    "    text = df.iloc[:, 0].values[k]\n",
    "    txt = re.sub(r'http\\S+', '', text)\n",
    "    txt = re.sub(r'[!@#$%^&*?><,./\\-+`~|:);(â¤}{]', '', txt)\n",
    "\n",
    "    text_tokens = word_tokenize(txt)\n",
    "\n",
    "    def detect_benglish(text_tokens):\n",
    "        benglish = False\n",
    "        for j in range(len(text_tokens)):\n",
    "            for i in range(len(text_tokens[j])):\n",
    "                detector = Translator()\n",
    "                txt = text_tokens[j]\n",
    "                if i < len(txt) - 1:\n",
    "                    if detector.detect(txt[i]).lang == 'bn' and detector.detect(txt[i + 1]).lang == 'en' and txt[\n",
    "                        i].isalpha() == True and txt[i + 1].isalpha() == True:\n",
    "                        benglish = True\n",
    "        return benglish\n",
    "\n",
    "    def handle_benglish(text_tokens):\n",
    "        for j in range(len(text_tokens)):\n",
    "            s = []\n",
    "            for i in range(len(text_tokens[j])):\n",
    "                detector = Translator()\n",
    "                txt = text_tokens[j]\n",
    "                if i < len(txt) - 1:\n",
    "                    if detector.detect(txt[i]).lang == 'bn' and detector.detect(txt[i + 1]).lang == 'en' and txt[\n",
    "                        i].isalpha() == True and txt[i + 1].isalpha() == True:\n",
    "                        s.append(i)\n",
    "                    if txt[i] == '|':\n",
    "                        s.append(i)\n",
    "            for i in range(len(s)):\n",
    "                txt = txt.replace(txt[s[i]], txt[s[i]] + \" \")\n",
    "            text_tokens[j] = txt\n",
    "        tstring = str(' '.join(text_tokens)).lower()\n",
    "        text_tokens = word_tokenize(tstring)\n",
    "        return text_tokens\n",
    "\n",
    "    remove_sw = [word for word in text_tokens if not word in sw]\n",
    "    un_items = np.unique(remove_sw)\n",
    "    r_sw = [wordnet_lemmatizer.lemmatize(w) for w in un_items]\n",
    "    bn_tokens = []\n",
    "\n",
    "    def tanslate_bengali(r_sw):\n",
    "        for i in range(len(r_sw)):\n",
    "            bn_tokens.append(translator.translate(r_sw[i], dest='bn').text)\n",
    "        return bn_tokens\n",
    "\n",
    "    bn_token = r_sw\n",
    "    df.iloc[:, 0].values[k] = ' '.join(bn_token)\n",
    "\n",
    "df.iloc[:, -1].value_counts()\n",
    "df.iloc[:, 0]\n",
    "\n",
    "df[:].iloc[:, 0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdf146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05389d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sentences = []\n",
    "train_sentences=df['comment'].values\n",
    "train_labels=df['nlabel'].values\n",
    "for i in range(train_sentences.shape[0]): \n",
    "    #print(train_sentences[i])\n",
    "    x=str(train_sentences[i])\n",
    "    training_sentences.append(x)\n",
    "    \n",
    "training_sentences=np.array(training_sentences)\n",
    "\n",
    "train_labels=keras.utils.to_categorical(train_labels)\n",
    "\n",
    "print(\"training_sentences shape: \"+str(training_sentences.shape))\n",
    "print(\"train_labels shape: \"+str(train_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871ca870",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_sentences[1])\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c3a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 20000\n",
    "embedding_dim = 300\n",
    "max_length = 100\n",
    "trunc_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "print(training_sentences.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb54e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "print(len(word_index))\n",
    "print(\"Word index length:\"+str(len(tokenizer.word_index)))\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb94435",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sentence :--> \\n\")\n",
    "print(training_sentences[15]+\"\\n\")\n",
    "print(\"Sentence Tokenized and Converted into Sequence :--> \\n\")\n",
    "print(str(sequences[15])+\"\\n\")\n",
    "print(\"After Padding the Sequence with padding length 100 :--> \\n\")\n",
    "print(padded[15])\n",
    "print(\"Padded shape(training): \"+str(padded.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5da6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6e1625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalanced Data Handling\n",
    "cc = InstanceHardnessThreshold(random_state=10, estimator=LogisticRegression())\n",
    "X, y = cc.fit_resample(padded, train_labels)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c277d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation\n",
    "kf = KFold(n_splits=5, random_state=10, shuffle=True)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    padded, train_labels = X[train_index], X[test_index]\n",
    "    testing_padded, testing_padded1 = y[train_index], y[test_index]\n",
    "print('complete')\n",
    "print('train:', padded.shape, train_labels.shape, 'test:', testing_padded.shape, testing_padded1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd20d769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce9ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a Sequential model\n",
    "cnn_model = Sequential()\n",
    "\n",
    "# Add an Embedding layer\n",
    "cnn_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
    "\n",
    "# Add a 1D Convolutional layer\n",
    "cnn_model.add(Conv1D(filters=200, kernel_size=3, activation='relu'))\n",
    "\n",
    "# Add a Global Max Pooling layer to reduce dimensionality\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# Add one or more Dense layers for classification\n",
    "cnn_model.add(Dense(50, activation='relu'))\n",
    "cnn_model.add(Dense(5, activation='softmax'))  # Assuming binary classification\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "cnn_model.summary()\n",
    "\n",
    "# Assuming you've trained the model using the provided code\n",
    "history = cnn_model.fit(padded, testing_padded, epochs=15, batch_size=32, validation_data=(train_labels, testing_padded1), use_multiprocessing=True, workers=8)\n",
    "\n",
    "loss_and_metrics = cnn_model.evaluate(train_labels, testing_padded1, batch_size=32)\n",
    "accuracy = loss_and_metrics[1]\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = cnn_model.predict(train_labels)\n",
    "y_pred_classes = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "# Convert one-hot encoded labels to integers\n",
    "y_true = tf.argmax(testing_padded1, axis=1)\n",
    "\n",
    "# Calculate Precision, Recall, and F1 Score\n",
    "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f\"CNN Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision*100:.2f}%\")\n",
    "print(f\"Recall: {recall*100:.2f}%\")\n",
    "print(f\"F1 Score: {f1*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee307a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(history.history.keys())\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('CNN model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()\n",
    "\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy= history.history['val_accuracy']\n",
    "plt.plot(accuracy)\n",
    "plt.plot(val_accuracy)\n",
    "plt.title('CNN model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.show()\n",
    "\n",
    "# Assuming you have already trained the model and obtained predictions\n",
    "predictions = cnn_model.predict(train_labels)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "actual_labels = np.argmax(testing_padded1, axis=1)\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(actual_labels, predicted_labels)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['not bully', 'troll', 'sexual', 'religious', 'threat']\n",
    "\n",
    "# Plot colorful confusion matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    " # Display values on the plot without box and color\n",
    "for i in range(len(class_names)):\n",
    "    for j in range(len(class_names)):\n",
    "        plt.text(j + 0.5, i + 0.5, f'{conf_matrix[i, j]}', ha='center', va='center', color='black', fontsize=10)\n",
    "# Set labels and title\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix CNN\")\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# ... (Previous code remains unchanged)\n",
    "\n",
    "# Predict probabilities for each class\n",
    "y_probs = cnn_model.predict(train_labels)\n",
    "\n",
    "# Convert one-hot encoded labels to integers\n",
    "y_true = np.argmax(testing_padded1, axis=1)\n",
    "\n",
    "class_names = ['Not Bully', 'Troll', 'Sexual', 'Religious', 'Threat']\n",
    "# Plot ROC curve for each class\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr, tpr, _ = roc_curve((y_true == i).astype(int), y_probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC curve with class names\n",
    "    plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# Plot diagonal line for reference\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Multi-Class Classification CNN')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa9e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# Model Definition - CLSTM\n",
    "clstm_model = Sequential()\n",
    "clstm_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
    "clstm_model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "clstm_model.add(MaxPooling1D(pool_size=2))\n",
    "clstm_model.add(LSTM(100, return_sequences=True))\n",
    "clstm_model.add(LSTM(100))\n",
    "clstm_model.add(Dense(50, activation='relu'))\n",
    "clstm_model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "adam = Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False)\n",
    "clstm_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "clstm_model.summary()\n",
    "\n",
    "# Training\n",
    "history = clstm_model.fit(padded, testing_padded, epochs=15, batch_size=32, validation_data=(train_labels, testing_padded1), use_multiprocessing=True, workers=8)\n",
    "\n",
    "# Evaluate Test Accuracy\n",
    "loss_and_metrics = clstm_model.evaluate(train_labels, testing_padded1, batch_size=32)\n",
    "accuracy = loss_and_metrics[1]\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = clstm_model.predict(train_labels)\n",
    "y_pred_classes = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "# Convert one-hot encoded labels to integers\n",
    "y_true = tf.argmax(testing_padded1, axis=1)\n",
    "\n",
    "# Calculate Precision, Recall, and F1 Score\n",
    "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision*100:.2f}%\")\n",
    "print(f\"Recall: {recall*100:.2f}%\")\n",
    "print(f\"F1 Score: {f1*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de19e687",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('CLSTM model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()\n",
    "\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy= history.history['val_accuracy']\n",
    "plt.plot(accuracy)\n",
    "plt.plot(val_accuracy)\n",
    "plt.title('CLSTM model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have already trained the model and obtained predictions\n",
    "predictions = clstm_model.predict(train_labels)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "actual_labels = np.argmax(testing_padded1, axis=1)\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(actual_labels, predicted_labels)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['not bully', 'troll', 'sexual', 'religious', 'threat']\n",
    "\n",
    "# Plot colorful confusion matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    " # Display values on the plot without box and color\n",
    "for i in range(len(class_names)):\n",
    "    for j in range(len(class_names)):\n",
    "        plt.text(j + 0.5, i + 0.5, f'{conf_matrix[i, j]}', ha='center', va='center', color='black', fontsize=10)\n",
    "# Set labels and title\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix CLSTM\")\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "# ... (Previous code remains unchanged)\n",
    "\n",
    "# Predict probabilities for each class\n",
    "y_probs = clstm_model.predict(train_labels)\n",
    "\n",
    "# Convert one-hot encoded labels to integers\n",
    "y_true = np.argmax(testing_padded1, axis=1)\n",
    "\n",
    "class_names = ['Not Bully', 'Troll', 'Sexual', 'Religious', 'Threat']\n",
    "# Plot ROC curve for each class\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr, tpr, _ = roc_curve((y_true == i).astype(int), y_probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC curve with class names\n",
    "    plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# Plot diagonal line for reference\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Multi-Class Classification CLSTM')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4cf85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Model Definition - RNN\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
    "rnn_model.add(SimpleRNN(100, return_sequences=True))  # Use LSTM if needed for longer-term dependencies\n",
    "rnn_model.add(SimpleRNN(100))\n",
    "rnn_model.add(Dense(50, activation='relu'))\n",
    "rnn_model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "adam = Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False)\n",
    "rnn_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "rnn_model.summary()\n",
    "\n",
    "# Training\n",
    "history = rnn_model.fit(padded, testing_padded, epochs=15, batch_size=32, validation_data=(train_labels, testing_padded1), use_multiprocessing=True, workers=8)\n",
    "\n",
    "# Evaluate Test Accuracy\n",
    "loss_and_metrics = rnn_model.evaluate(train_labels, testing_padded1, batch_size=32)\n",
    "accuracy = loss_and_metrics[1]\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = rnn_model.predict(train_labels)\n",
    "y_pred_classes = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "# Convert one-hot encoded labels to integers\n",
    "y_true = tf.argmax(testing_padded1, axis=1)\n",
    "\n",
    "# Calculate Precision, Recall, and F1 Score\n",
    "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision*100:.2f}%\")\n",
    "print(f\"Recall: {recall*100:.2f}%\")\n",
    "print(f\"F1 Score: {f1*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c511c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('RNN model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()\n",
    "\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy= history.history['val_accuracy']\n",
    "plt.plot(accuracy)\n",
    "plt.plot(val_accuracy)\n",
    "plt.title('RNN model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.show()\n",
    "\n",
    "# Assuming you have already trained the model and obtained predictions\n",
    "predictions = rnn_model.predict(train_labels)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "actual_labels = np.argmax(testing_padded1, axis=1)\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(actual_labels, predicted_labels)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['not bully', 'troll', 'sexual', 'religious', 'threat']\n",
    "\n",
    "# Plot colorful confusion matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    " # Display values on the plot without box and color\n",
    "for i in range(len(class_names)):\n",
    "    for j in range(len(class_names)):\n",
    "        plt.text(j + 0.5, i + 0.5, f'{conf_matrix[i, j]}', ha='center', va='center', color='black', fontsize=10)\n",
    "# Set labels and title\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix RNN\")\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Predict probabilities for each class\n",
    "y_probs = rnn_model.predict(train_labels)\n",
    "\n",
    "# Convert one-hot encoded labels to integers\n",
    "y_true = np.argmax(testing_padded1, axis=1)\n",
    "\n",
    "class_names = ['Not Bully', 'Troll', 'Sexual', 'Religious', 'Threat']\n",
    "# Plot ROC curve for each class\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr, tpr, _ = roc_curve((y_true == i).astype(int), y_probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC curve with class names\n",
    "    plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# Plot diagonal line for reference\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Multi-Class Classification RNN')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4e21fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, GRU, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Model Definition - BiGRU\n",
    "bigru_model = Sequential()\n",
    "bigru_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
    "bigru_model.add(Bidirectional(GRU(100, return_sequences=True)))\n",
    "bigru_model.add(Bidirectional(GRU(100)))\n",
    "bigru_model.add(Dense(50, activation='relu'))\n",
    "bigru_model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "adam = Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False)\n",
    "bigru_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "bigru_model.summary()\n",
    "\n",
    "# Training\n",
    "history = bigru_model.fit(padded, testing_padded, epochs=15, batch_size=32, validation_data=(train_labels, testing_padded1), use_multiprocessing=True, workers=8)\n",
    "\n",
    "# Evaluate Test Accuracy\n",
    "loss_and_metrics = bigru_model.evaluate(train_labels, testing_padded1, batch_size=32)\n",
    "accuracy = loss_and_metrics[1]\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = bigru_model.predict(train_labels)\n",
    "y_pred_classes = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "# Convert one-hot encoded labels to integers\n",
    "y_true = tf.argmax(testing_padded1, axis=1)\n",
    "\n",
    "# Calculate Precision, Recall, and F1 Score\n",
    "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision*100:.2f}%\")\n",
    "print(f\"Recall: {recall*100:.2f}%\")\n",
    "print(f\"F1 Score: {f1*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f3b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('BiGRU model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()\n",
    "\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy= history.history['val_accuracy']\n",
    "plt.plot(accuracy)\n",
    "plt.plot(val_accuracy)\n",
    "plt.title('BiGRU model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have already trained the model and obtained predictions\n",
    "predictions = bigru_model.predict(train_labels)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "actual_labels = np.argmax(testing_padded1, axis=1)\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(actual_labels, predicted_labels)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['not bully', 'troll', 'sexual', 'religious', 'threat']\n",
    "\n",
    "# Plot colorful confusion matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    " # Display values on the plot without box and color\n",
    "for i in range(len(class_names)):\n",
    "    for j in range(len(class_names)):\n",
    "        plt.text(j + 0.5, i + 0.5, f'{conf_matrix[i, j]}', ha='center', va='center', color='black', fontsize=10)\n",
    "# Set labels and title\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix BiGRU\")\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "# ... (Previous code remains unchanged)\n",
    "\n",
    "# Predict probabilities for each class\n",
    "y_probs = bigru_model.predict(train_labels)\n",
    "\n",
    "# Convert one-hot encoded labels to integers\n",
    "y_true = np.argmax(testing_padded1, axis=1)\n",
    "\n",
    "class_names = ['Not Bully', 'Troll', 'Sexual', 'Religious', 'Threat']\n",
    "# Plot ROC curve for each class\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr, tpr, _ = roc_curve((y_true == i).astype(int), y_probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC curve with class names\n",
    "    plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# Plot diagonal line for reference\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Multi-Class Classification BiGRU')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fef4918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Model Definition - DNN\n",
    "dnn_model = Sequential()\n",
    "dnn_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
    "dnn_model.add(Flatten())\n",
    "dnn_model.add(Dense(256, activation='relu'))\n",
    "dnn_model.add(Dense(128, activation='relu'))\n",
    "dnn_model.add(Dense(64, activation='relu'))\n",
    "dnn_model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "adam = Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False)\n",
    "dnn_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "dnn_model.summary()\n",
    "\n",
    "# Training\n",
    "history = dnn_model.fit(padded, testing_padded, epochs=15, batch_size=32, validation_data=(train_labels, testing_padded1), use_multiprocessing=True, workers=8)\n",
    "\n",
    "# Evaluate Test Accuracy\n",
    "loss_and_metrics = dnn_model.evaluate(train_labels, testing_padded1, batch_size=32)\n",
    "accuracy = loss_and_metrics[1]\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = dnn_model.predict(train_labels)\n",
    "y_pred_classes = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "# Convert one-hot encoded labels to integers\n",
    "y_true = tf.argmax(testing_padded1, axis=1)\n",
    "\n",
    "# Calculate Precision, Recall, and F1 Score\n",
    "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision*100:.2f}%\")\n",
    "print(f\"Recall: {recall*100:.2f}%\")\n",
    "print(f\"F1 Score: {f1*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5218b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('DNN model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()\n",
    "\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy= history.history['val_accuracy']\n",
    "plt.plot(accuracy)\n",
    "plt.plot(val_accuracy)\n",
    "plt.title('DNN model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have already trained the model and obtained predictions\n",
    "predictions = dnn_model.predict(train_labels)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "actual_labels = np.argmax(testing_padded1, axis=1)\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(actual_labels, predicted_labels)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['not bully', 'troll', 'sexual', 'religious', 'threat']\n",
    "\n",
    "# Plot colorful confusion matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    " # Display values on the plot without box and color\n",
    "for i in range(len(class_names)):\n",
    "    for j in range(len(class_names)):\n",
    "        plt.text(j + 0.5, i + 0.5, f'{conf_matrix[i, j]}', ha='center', va='center', color='black', fontsize=10)\n",
    "# Set labels and title\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix DNN\")\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "# ... (Previous code remains unchanged)\n",
    "\n",
    "# Predict probabilities for each class\n",
    "y_probs = dnn_model.predict(train_labels)\n",
    "\n",
    "# Convert one-hot encoded labels to integers\n",
    "y_true = np.argmax(testing_padded1, axis=1)\n",
    "\n",
    "class_names = ['Not Bully', 'Troll', 'Sexual', 'Religious', 'Threat']\n",
    "# Plot ROC curve for each class\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr, tpr, _ = roc_curve((y_true == i).astype(int), y_probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC curve with class names\n",
    "    plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# Plot diagonal line for reference\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Multi-Class Classification DNN')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
